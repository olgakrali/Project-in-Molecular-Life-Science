# Friday 9 March, 2018

After a long night of studying and coding, a long night and day of waiting the cross validation results, I got the best parameters and window
size for my data. I ran cross validation for the window sizes separately from my parameters, because I tried it yesterday and it took very long time
and I did not want to miss the deadline. It was faster and it gave me very good results. More specifically, the ideal window size for my case
is 19. The parameters I had for my SVC was linear kernel, C = 1 and gamma  = 0.01. The scores can be found on the Docs/Evaluation_scores folder.

After that step, I utilized sklearn's joblib to save my svm model, I ran it on a train set of 60 proteins. Then I loaded the model from another
Python script to run it for a test set of 30 proteins. This script when it runs, it gives as an output a confussion matrix of the normalized
topology predictions and creates a file that includes the protein_ID, sequence, topology and predicted topology.

The file that has to run for this deadline is Source_codes/SVM/run_my_SVM_model_test_set.py , which loads the Saved_models/my_test.sav
and creates the file Datasets/true_vs_predicted_topo.txt.

Finally, I feel relieved that I did this part, because now I know how to proceed with the other 2 classifiers during the next days. While I was
looking my true_vs_predicted_topo.txt file, I saw that the predictions were not that bad as I expected to. I thought that since I had so many
globular residues, I would have gotten wrong prediction. But luckily it worked well. In any case, I will make a table for the true positive,
true negative, false positive and false negative values to see clearly what is happening. 
