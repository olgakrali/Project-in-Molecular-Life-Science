# Monday 5 March, 2018
# Week for predictor optimization and data implementation on other classifiers


Today I went to the lab and I got some interesting feedback from David. I will update a few things to my GitHub account these days by removing older scripts and 
keeping the newest versions. David suggested to do PCA transformation and reduction of multidimensionality and then run my SVM, which it did not gave better
results (I chose n_components from 2 - 20). But I would like to write about that on my paper, while I will describe the different methods I followed. He also mentioned
to use normalized data for my confusion matrix to get a better understanding over my predicted topologies. I also tranformed the predicted values into topologies, because the integers
are just for running the classifiers.

John mentioned that my data are biased, because most of my proteins have globular domains and there is high probability my model to be good for predicting Globular
topologies only. Thus, he suggested to get my topologies into % form and see with what % each topology is represented on my data. After running the SVM, I could also get the % of each
topology that was predicted right, represented as a % of the total % of each topology. 

Although I selected my test set and my data set randomly for the previous tasks, I did it manually and that could rise biases later. Today, I wrote a script that can take
a txt file as an input and when it runs, it splits randomly my dataset into train and test set. I tried it on my original dataset, but it works for every file I would
use as a input.

My goals for these days:

1) SVM model evaluation by running for loops containing different kernel types, CVs, gammas, window sizes etc. I did it manually, but it would be good to have it on a script.

2) Make RandomForest and One Simple desicion tree classifiers and repeat the evaluation processes. I will produced a confussion matrix for the best models.

3) Run PSI-BLAST and use the evolutionary information for running again my SVM.



