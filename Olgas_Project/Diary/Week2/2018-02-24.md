# Saturday 24 February, 2018

# Cross validation and Support Vector Machine

Today I finished with cross-validation and svm models, since I managed to get the input values (X,y) for the sklearn svm function. I ran my code for various proteins to see how good is the score of the prediction. While running svc(), I got quite bad predictions for my proteins, but when I added the condition kernel = 'linear' the results were much better. I made also a plot for visualization of the true values(classes of 1,2 or 3 from my topologies) versus the predicted y values. 

I was trying different methods of spliting my data into training and test set, such as with the sklearn function train_test_split, but while I was reading I realised that the way to get reliable predictions is to use cross validation, which splits the data into training and validation sets. If for example the cv = 5, the dataset is splitted into 5 folds and everytime each fold is used as a validation set (5 iterations using one of the 5 validation sets). With cross validation we can avoid model overfitting compared to splitting into training and test set with the first method.


